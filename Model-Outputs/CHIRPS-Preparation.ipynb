{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib.request\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import unrasterize\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAAS_ENDPOINT = \"https://model-service.worldmodelers.com/\"\n",
    "#conn = psycopg2.connect(host=\"maas.cowfye1azh5f.us-east-1.rds.amazonaws.com\",database=\"output\", user=\"wmuser\", password=\"REPLACEME\")\n",
    "#cur = conn.cursor()\n",
    "user = \"wmuser\"\n",
    "password = \"Bq248mQHV9EDuUap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all training data (configs + outputs)\n",
    "def get_training_data(model_name):\n",
    "    response = requests.get(MAAS_ENDPOINT + \"list_runs/\" + model_name)\n",
    "    run_ids = json.loads(response.text)\n",
    "    \n",
    "    datas = []\n",
    "    configs = []\n",
    "    for rid in run_ids:\n",
    "        #rid = rid.lower()\n",
    "        config_response = requests.get(MAAS_ENDPOINT + \"run_results/\" + rid)\n",
    "        config = json.loads(config_response.text)        \n",
    "        statement = f\"SELECT * FROM rundata where run_id = '{rid}';\"\n",
    "        cur.execute(statement)\n",
    "        print(cur.fetchall())\n",
    "        output_df = pd.DataFrame(cur.fetchall(),columns=['run_id', 'x', 'y','id','feature','datetime'])\n",
    "        datas.append(output_df)\n",
    "        configs.append(config)\n",
    "            \n",
    "    return configs, datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(.0000000011,1.25,.24999999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{\n",
    "   \"config\":{\n",
    "      \"_type\": 'mm_data',\n",
    "      \"dekad\": '01',\n",
    "      \"year\": 2019\n",
    "   },\n",
    "   \"name\":\"CHIRPS\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "d = pd.read_csv(\"/Users/jgawrilow/single_shock_results.csv\")\n",
    "countries = list(d.country)\n",
    "#countries = [\"ETH\"]\n",
    "_type = [\"mm_data\"]\n",
    "dekad = map(lambda x: str(x).zfill(2),range(1,37))\n",
    "year = list(range(2019,1980,-1))\n",
    "mmatrix = list(itertools.product(*[_type,year,dekad]))\n",
    "print(mmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "run_matrix = {\n",
    "    \"x\":range(0,100),\n",
    "    \"y\":[\"A\",\"B\",\"C\"],\n",
    "    \"z\":[\"Z\",\"Y\",\"X\"]\n",
    "}\n",
    "\n",
    "test = [[1,2,3],[4,5,6]]\n",
    "\n",
    "result = list(itertools.product(*test))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if params are \n",
    "-- x float [0-100]\n",
    "-- y A B C\n",
    "-- z Z Y Z\n",
    "\"\"\"\n",
    "\n",
    "run_matrix = {\n",
    "    \"x\":range(0,100),\n",
    "    \"y\":[\"A\",\"B\",\"C\"],\n",
    "    \"z\":[\"Z\",\"Y\",\"X\"]\n",
    "}\n",
    "\n",
    "def range_to_list(x):\n",
    "    vals = []\n",
    "    k = x.keys()[0]\n",
    "    for v in x[k]:\n",
    "        vals.append({k:v})\n",
    "        \n",
    "#result = list(itertools.product(*inputdata))\n",
    "    \n",
    "\n",
    "# continuously run model and cache outputs\n",
    "def run_and_cache(session,model_name,runs,fields):\n",
    "    \n",
    "    for j, run in enumerate(runs):\n",
    "        mydata = {\n",
    "           \"config\":{},\n",
    "           \"name\":model_name\n",
    "        }\n",
    "        for i, field in enumerate(fields):\n",
    "            mydata[\"config\"][field] = run[i]\n",
    "\n",
    "        URL = MAAS_ENDPOINT + \"run_model\"\n",
    "        #print(json.dumps(mydata))\n",
    "        resp = session.post(URL, json=mydata)\n",
    "        rid = resp.text.replace('\"',\"\").strip()\n",
    "        time.sleep(2)\n",
    "        run_response = session.get(MAAS_ENDPOINT + \"run_status/\" + rid)\n",
    "        STATUS = run_response.text.replace('\"',\"\").strip()\n",
    "        print(j, rid, STATUS)\n",
    "\n",
    "        while STATUS != \"SUCCESS\" and STATUS != \"FAIL\":\n",
    "            time.sleep(1)\n",
    "            URL = MAAS_ENDPOINT + \"run_status/\" + rid\n",
    "            run_response = session.get(MAAS_ENDPOINT + \"run_status/\" + rid)\n",
    "            STATUS = run_response.text.replace('\"',\"\").strip()\n",
    "            print(j, rid, STATUS)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, datas = get_training_data(\"DSSAT\")\n",
    "print(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.auth = (user, password)\n",
    "run_and_cache(session,\"CHIRPS\",mmatrix,[\"_type\",\"year\",\"dekad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.auth = (user, password)\n",
    "print(session.get(MAAS_ENDPOINT + \"available_results\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def prep_p(session,model_name,runs,fields):\n",
    "    \n",
    "    dfs = {}\n",
    "    out = open(\"chirps_runs.json\",\"w\")\n",
    "    for run in runs:\n",
    "        mydata = {\n",
    "           \"config\":{},\n",
    "           \"name\":model_name\n",
    "        }\n",
    "        for i, field in enumerate(fields):\n",
    "            mydata[\"config\"][field] = run[i]\n",
    "\n",
    "        URL = MAAS_ENDPOINT + \"run_model\"\n",
    "        print(json.dumps(mydata))\n",
    "        resp = session.post(URL, json=mydata)\n",
    "        rid = resp.text.replace('\"',\"\").strip()\n",
    "        dfs[rid] = mydata\n",
    "        run_response = session.get(MAAS_ENDPOINT + \"run_status/\" + rid)\n",
    "        STATUS = run_response.text.replace('\"',\"\").strip()\n",
    "    out.write(json.dumps(dfs,indent=2))\n",
    "    out.close()\n",
    "#         if STATUS == \"SUCCESS\":\n",
    "#             URL = MAAS_ENDPOINT + \"run_results\"\n",
    "#             run_response = session.get(MAAS_ENDPOINT + \"run_results/\" + rid)\n",
    "#             outloc = json.loads(run_response.text)[\"output\"]\n",
    "#             wget.download(outloc,\"./runs/\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.auth = (user, password)\n",
    "prep_p(session,\"CHIRPS\",mmatrix,[\"_type\",\"year\",\"dekad\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS 2017 - 2019\n",
    "Below pulls in anomaly and data information for 2017 - 2019.\n",
    "\n",
    "These rasters are converted to coarse grained CSVs and prepped for Tableau ingestion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CHIRPS for 2017 - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_dekad(d):\n",
    "    if d < 10:\n",
    "        return f\"0{d}\"\n",
    "    else:\n",
    "        return f\"{d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2017, 2018, 2019]\n",
    "dekads = [pad_dekad(i) for i in range(1, 36)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.auth = (user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = MAAS_ENDPOINT + \"run_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is longitude, y is latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW=(1.149689, 21.702228)\n",
    "NE=(16.162925, 50.055588)\n",
    "xmin = 21.702228\n",
    "xmax = 50.055588\n",
    "ymin = 1.149689\n",
    "ymax = 16.162925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for dekad in dekads:\n",
    "        payload = {\n",
    "               \"config\":{\n",
    "                  \"_type\": \"mm_data\",\n",
    "                  \"dekad\": dekad,\n",
    "                  \"year\": year,\n",
    "                  \"bbox\": [xmin, ymin, xmax, ymax]\n",
    "               },\n",
    "               \"name\":\"CHIRPS\"\n",
    "            }\n",
    "        resp = session.post(URL, json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = MAAS_ENDPOINT + \"available_results\"\n",
    "CHIRPS_results = session.get(URL + \"?ModelName=CHIRPS\")\n",
    "CHIRPS_results = [i for i in CHIRPS_results.json() if i['config']['config']['year']>=2017]\n",
    "CHIRPS_results = [i for i in CHIRPS_results if i['config']['config']['_type']=='mm_data']\n",
    "CHIRPS_results = [i for i in CHIRPS_results if 'bbox' in i['config']['config']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CHIRPS_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in CHIRPS_results:\n",
    "    year = i['config']['config']['year']\n",
    "    dekad = i['config']['config']['dekad']\n",
    "    uri = i['output']\n",
    "    obj = {\"year\": year, \"dekad\": dekad, \"uri\":uri}\n",
    "    rows.append(obj)\n",
    "    \n",
    "df = pd.DataFrame(rows)\n",
    "df = df.sort_values(['year','dekad']).reset_index()\n",
    "df = df[['year','dekad','uri']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for kk, vv in df.iterrows():\n",
    "    print(vv.year, vv.dekad)\n",
    "    urllib.request.urlretrieve(vv.uri, f'CHIRPS/{vv.year}-{vv.dekad}.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CHIRPS Anomalies for 2017 - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.auth = (user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = MAAS_ENDPOINT + \"run_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is longitude, y is latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW=(1.149689, 21.702228)\n",
    "NE=(16.162925, 50.055588)\n",
    "xmin = 21.702228\n",
    "xmax = 50.055588\n",
    "ymin = 1.149689\n",
    "ymax = 16.162925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for dekad in dekads:\n",
    "        payload = {\n",
    "               \"config\":{\n",
    "                  \"_type\": \"mm_anomaly\",\n",
    "                  \"dekad\": dekad,\n",
    "                  \"year\": year,\n",
    "                  \"bbox\": [xmin, ymin, xmax, ymax]\n",
    "               },\n",
    "               \"name\":\"CHIRPS\"\n",
    "            }\n",
    "        resp = session.post(URL, json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = MAAS_ENDPOINT + \"available_results\"\n",
    "CHIRPS_results = session.get(URL + \"?ModelName=CHIRPS\")\n",
    "CHIRPS_results = [i for i in CHIRPS_results.json() if i['config']['config']['year']>=2017]\n",
    "CHIRPS_anomalies = [i for i in CHIRPS_results if i['config']['config']['_type']=='mm_anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CHIRPS_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in CHIRPS_anomalies:\n",
    "    year = i['config']['config']['year']\n",
    "    dekad = i['config']['config']['dekad']\n",
    "    uri = i['output']\n",
    "    obj = {\"year\": year, \"dekad\": dekad, \"uri\":uri}\n",
    "    rows.append(obj)\n",
    "    \n",
    "df_anom = pd.DataFrame(rows)\n",
    "df_anom = df_anom.sort_values(['year','dekad']).reset_index()\n",
    "df_anom = df_anom[['year','dekad','uri']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for kk, vv in df_anom.iterrows():\n",
    "    print(vv.year, vv.dekad)\n",
    "    urllib.request.urlretrieve(vv.uri, f'CHIRPS-Anomalies/{vv.year}-{vv.dekad}.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert CHIRPS to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_csv_from_CHIRPS(raster_path, out_path, mask_width=6, threshold=0):\n",
    "    \"\"\"\n",
    "    Decrease mask_width for higher fidelity (finer grained); increase it for lower fidelity (course grained).\n",
    "    \"\"\"\n",
    "    raster_data = rasterio.open(raster_path)\n",
    "    \n",
    "    # Since unrasterize *sums* across pixels as it simplifies\n",
    "    # We need to count total pixels above our threshold to get the mean for the area of interest\n",
    "    total_pixels = len(raster_data.read(1)[raster_data.read(1)>threshold])\n",
    "    \n",
    "    # threshold to zero means that no negative pixels (missing data) are included\n",
    "    unrasterizer = unrasterize.WindowedUnrasterizer(mask_width=mask_width, threshold=threshold)\n",
    "    unrasterizer.select_representative_pixels(raster_data)\n",
    "    gdf = unrasterizer.to_geopandas(value_attribute_name='rainfall', crs=raster_data.crs)\n",
    "    gdf['latitude'] = gdf.geometry.apply(lambda x: x.bounds[1])\n",
    "    gdf['longitude'] = gdf.geometry.apply(lambda x: x.bounds[0])\n",
    "    \n",
    "    # Adjust rainfall by number of pixels (original) per new pixel\n",
    "    # Basically, get the mean of pixels that were aggregated\n",
    "    gdf['rainfall'] = gdf.rainfall.apply(lambda x: x/(total_pixels/gdf.shape[0]))\n",
    "    \n",
    "    gdf[['rainfall','latitude','longitude']].to_csv(out_path)\n",
    "    print(f\"Converted raster to {gdf.shape[0]} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chirps_mm = [i for i in os.listdir('CHIRPS') if 'tiff' in i]\n",
    "chirps_anomalies = [i for i in os.listdir('CHIRPS-Anomalies') if 'tiff' in i]\n",
    "chirps_mm.sort()\n",
    "chirps_anomalies.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted raster to 1332 points\n",
      "Converted raster to 1230 points\n",
      "Converted raster to 1360 points\n",
      "Converted raster to 1359 points\n",
      "Converted raster to 1482 points\n",
      "Converted raster to 1568 points\n",
      "Converted raster to 1862 points\n",
      "Converted raster to 1857 points\n",
      "Converted raster to 2058 points\n",
      "Converted raster to 2171 points\n",
      "Converted raster to 2250 points\n",
      "Converted raster to 2417 points\n",
      "Converted raster to 2558 points\n",
      "Converted raster to 2582 points\n",
      "Converted raster to 2574 points\n",
      "Converted raster to 2467 points\n",
      "Converted raster to 2192 points\n",
      "Converted raster to 2327 points\n",
      "Converted raster to 2493 points\n",
      "Converted raster to 2434 points\n",
      "Converted raster to 2455 points\n",
      "Converted raster to 2454 points\n",
      "Converted raster to 2481 points\n",
      "Converted raster to 2549 points\n",
      "Converted raster to 2437 points\n",
      "Converted raster to 2403 points\n",
      "Converted raster to 2524 points\n",
      "Converted raster to 2538 points\n",
      "Converted raster to 2448 points\n",
      "Converted raster to 2379 points\n",
      "Converted raster to 2208 points\n",
      "Converted raster to 1867 points\n",
      "Converted raster to 1787 points\n",
      "Converted raster to 1482 points\n",
      "Converted raster to 1322 points\n",
      "Converted raster to 706 points\n",
      "Converted raster to 1337 points\n",
      "Converted raster to 1208 points\n",
      "Converted raster to 1311 points\n",
      "Converted raster to 1347 points\n",
      "Converted raster to 1436 points\n",
      "Converted raster to 1650 points\n",
      "Converted raster to 1847 points\n",
      "Converted raster to 1904 points\n",
      "Converted raster to 2142 points\n",
      "Converted raster to 2213 points\n",
      "Converted raster to 2264 points\n",
      "Converted raster to 2408 points\n",
      "Converted raster to 2530 points\n",
      "Converted raster to 2497 points\n",
      "Converted raster to 2539 points\n",
      "Converted raster to 2471 points\n",
      "Converted raster to 2163 points\n",
      "Converted raster to 2341 points\n",
      "Converted raster to 2487 points\n",
      "Converted raster to 2439 points\n",
      "Converted raster to 2477 points\n",
      "Converted raster to 2424 points\n",
      "Converted raster to 2437 points\n",
      "Converted raster to 2496 points\n",
      "Converted raster to 2437 points\n",
      "Converted raster to 2346 points\n",
      "Converted raster to 2479 points\n",
      "Converted raster to 2556 points\n",
      "Converted raster to 2444 points\n",
      "Converted raster to 2483 points\n",
      "Converted raster to 2195 points\n",
      "Converted raster to 1850 points\n",
      "Converted raster to 1842 points\n",
      "Converted raster to 1665 points\n",
      "Converted raster to 1457 points\n",
      "Converted raster to 1119 points\n",
      "Converted raster to 1332 points\n",
      "Converted raster to 1238 points\n",
      "Converted raster to 1368 points\n",
      "Converted raster to 1335 points\n",
      "Converted raster to 1381 points\n",
      "Converted raster to 1579 points\n",
      "Converted raster to 1763 points\n",
      "Converted raster to 1859 points\n",
      "Converted raster to 2070 points\n",
      "Converted raster to 2233 points\n",
      "Converted raster to 2302 points\n",
      "Converted raster to 2302 points\n",
      "Converted raster to 2499 points\n",
      "Converted raster to 2540 points\n",
      "Converted raster to 2596 points\n",
      "Converted raster to 2540 points\n",
      "Converted raster to 2250 points\n",
      "Converted raster to 2364 points\n",
      "Converted raster to 2465 points\n",
      "Converted raster to 2466 points\n",
      "Converted raster to 2469 points\n",
      "Converted raster to 2442 points\n",
      "Converted raster to 2450 points\n",
      "Converted raster to 2554 points\n",
      "Converted raster to 2461 points\n",
      "Converted raster to 2382 points\n",
      "Converted raster to 2542 points\n",
      "'CHIRPS/2019-28.tiff' not recognized as a supported file format.\n",
      "'CHIRPS/2019-29.tiff' not recognized as a supported file format.\n",
      "'CHIRPS/2019-30.tiff' not recognized as a supported file format.\n",
      "'CHIRPS/2019-31.tiff' not recognized as a supported file format.\n",
      "'CHIRPS/2019-32.tiff' not recognized as a supported file format.\n",
      "'CHIRPS/2019-33.tiff' not recognized as a supported file format.\n",
      "'CHIRPS/2019-34.tiff' not recognized as a supported file format.\n",
      "'CHIRPS/2019-35.tiff' not recognized as a supported file format.\n",
      "'CHIRPS/2019-36.tiff' not recognized as a supported file format.\n",
      "Converted raster to 2645 points\n",
      "Converted raster to 2611 points\n",
      "Converted raster to 2611 points\n",
      "Converted raster to 2632 points\n",
      "Converted raster to 2620 points\n",
      "Converted raster to 2610 points\n",
      "Converted raster to 2620 points\n",
      "Converted raster to 2634 points\n",
      "Converted raster to 2644 points\n",
      "Converted raster to 2641 points\n",
      "Converted raster to 2680 points\n",
      "Converted raster to 2609 points\n",
      "Converted raster to 2632 points\n",
      "Converted raster to 2626 points\n",
      "Converted raster to 2613 points\n",
      "Converted raster to 2658 points\n",
      "Converted raster to 2630 points\n",
      "Converted raster to 2620 points\n",
      "Converted raster to 2601 points\n",
      "Converted raster to 2661 points\n",
      "Converted raster to 2622 points\n",
      "Converted raster to 2611 points\n",
      "Converted raster to 2647 points\n",
      "Converted raster to 2625 points\n",
      "Converted raster to 2638 points\n",
      "Converted raster to 2624 points\n",
      "Converted raster to 2623 points\n",
      "Converted raster to 2637 points\n",
      "Converted raster to 2672 points\n",
      "Converted raster to 2676 points\n",
      "Converted raster to 2635 points\n",
      "Converted raster to 2644 points\n",
      "Converted raster to 2610 points\n",
      "Converted raster to 2639 points\n",
      "Converted raster to 2632 points\n",
      "Converted raster to 2681 points\n",
      "Converted raster to 2664 points\n",
      "Converted raster to 2623 points\n",
      "Converted raster to 2634 points\n",
      "Converted raster to 2601 points\n",
      "Converted raster to 2602 points\n",
      "Converted raster to 2592 points\n",
      "Converted raster to 2631 points\n",
      "Converted raster to 2631 points\n",
      "Converted raster to 2649 points\n",
      "Converted raster to 2639 points\n",
      "Converted raster to 2686 points\n",
      "Converted raster to 2603 points\n",
      "Converted raster to 2621 points\n",
      "Converted raster to 2652 points\n",
      "Converted raster to 2615 points\n",
      "Converted raster to 2667 points\n",
      "Converted raster to 2631 points\n",
      "Converted raster to 2616 points\n",
      "Converted raster to 2613 points\n",
      "Converted raster to 2588 points\n",
      "Converted raster to 2668 points\n",
      "Converted raster to 2592 points\n",
      "Converted raster to 2602 points\n",
      "Converted raster to 2587 points\n",
      "Converted raster to 2626 points\n",
      "Converted raster to 2613 points\n",
      "Converted raster to 2672 points\n",
      "Converted raster to 2670 points\n",
      "Converted raster to 2670 points\n",
      "Converted raster to 2612 points\n",
      "Converted raster to 2658 points\n",
      "Converted raster to 2614 points\n",
      "Converted raster to 2547 points\n",
      "Converted raster to 2590 points\n",
      "Converted raster to 2605 points\n",
      "Converted raster to 2643 points\n",
      "Converted raster to 1321 points\n",
      "Converted raster to 2597 points\n",
      "Converted raster to 2600 points\n",
      "Converted raster to 2625 points\n",
      "Converted raster to 2613 points\n",
      "Converted raster to 2575 points\n",
      "Converted raster to 2648 points\n",
      "Converted raster to 2655 points\n",
      "Converted raster to 2617 points\n",
      "Converted raster to 2626 points\n",
      "Converted raster to 2667 points\n",
      "Converted raster to 2654 points\n",
      "Converted raster to 2657 points\n",
      "Converted raster to 2648 points\n",
      "Converted raster to 2621 points\n",
      "Converted raster to 2683 points\n",
      "Converted raster to 2667 points\n",
      "Converted raster to 2653 points\n",
      "Converted raster to 2628 points\n",
      "Converted raster to 2603 points\n",
      "Converted raster to 2637 points\n",
      "Converted raster to 2610 points\n",
      "Converted raster to 2638 points\n",
      "Converted raster to 2607 points\n",
      "Converted raster to 2615 points\n",
      "Converted raster to 2655 points\n",
      "Converted raster to 2638 points\n",
      "'CHIRPS-Anomalies/2019-28.tiff' not recognized as a supported file format.\n",
      "'CHIRPS-Anomalies/2019-29.tiff' not recognized as a supported file format.\n",
      "'CHIRPS-Anomalies/2019-30.tiff' not recognized as a supported file format.\n",
      "'CHIRPS-Anomalies/2019-31.tiff' not recognized as a supported file format.\n",
      "'CHIRPS-Anomalies/2019-32.tiff' not recognized as a supported file format.\n",
      "'CHIRPS-Anomalies/2019-33.tiff' not recognized as a supported file format.\n",
      "'CHIRPS-Anomalies/2019-34.tiff' not recognized as a supported file format.\n",
      "'CHIRPS-Anomalies/2019-35.tiff' not recognized as a supported file format.\n",
      "'CHIRPS-Anomalies/2019-36.tiff' not recognized as a supported file format.\n"
     ]
    }
   ],
   "source": [
    "for path in chirps_mm:\n",
    "    in_path = f\"CHIRPS/{path}\"\n",
    "    out_path = f\"CHIRPS/{path.split('.tiff')[0]+'.csv'}\"\n",
    "    try:\n",
    "        gen_csv_from_CHIRPS(in_path, out_path)\n",
    "    except Exception as e:\n",
    "        # likely due to a bad file for dates we have not reached yet        \n",
    "        print(e)\n",
    "        \n",
    "for path in chirps_anomalies:\n",
    "    in_path = f\"CHIRPS-Anomalies/{path}\"\n",
    "    out_path = f\"CHIRPS-Anomalies/{path.split('.tiff')[0]+'.csv'}\"\n",
    "    try:\n",
    "        gen_csv_from_CHIRPS(in_path, out_path, threshold=-8000) # set a threshold, -9999 is missing        \n",
    "    except Exception as e:\n",
    "        # likely due to a bad file for dates we have not reached yet\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process CHIRPS CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chirps_mm = [i for i in os.listdir('CHIRPS') if 'csv' in i]\n",
    "chirps_anomalies = [i for i in os.listdir('CHIRPS-Anomalies') if 'csv' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "for path in chirps_mm:\n",
    "    df_ = pd.read_csv(f\"CHIRPS/{path}\")[['rainfall','latitude','longitude']]\n",
    "    df_['year'] = path.split('-')[0]\n",
    "    df_['dekad'] = path.split('-')[1].split('.csv')[0]\n",
    "    df_['type'] = 'mm_data'\n",
    "    if first == True:\n",
    "        df_combined = df_\n",
    "        first = False\n",
    "    else:\n",
    "        df_combined = df_combined.append(df_)\n",
    "        \n",
    "for path in chirps_anomalies:\n",
    "    df_ = pd.read_csv(f\"CHIRPS-Anomalies/{path}\")[['rainfall','latitude','longitude']]\n",
    "    df_['year'] = path.split('-')[0]\n",
    "    df_['dekad'] = path.split('-')[1].split('.csv')[0]\n",
    "    df_['type'] = 'mm_anomaly'\n",
    "    df_combined = df_combined.append(df_)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466735, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type        year\n",
       "mm_anomaly  2017    94814\n",
       "            2018    94527\n",
       "            2019    69758\n",
       "mm_data     2017    74613\n",
       "            2018    75241\n",
       "            2019    57782\n",
       "Name: dekad, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.groupby([\"type\",\"year\"])['dekad'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dekad(year, dekad):\n",
    "    dt = datetime.datetime(int(year), 1, 1)\n",
    "    dtdelta = datetime.timedelta(int(dekad) * 10 - 1)\n",
    "    date = dt + dtdelta\n",
    "    return date.strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dekad/year to a mm-dd-yyyy timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['date'] = df_combined.apply(lambda x: process_dekad(x.year, x.dekad), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"month\"] = df_combined.date.apply(lambda x: int(x.split('-')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rainfall</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>dekad</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.930994</td>\n",
       "      <td>4.570738</td>\n",
       "      <td>21.876941</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>mm_data</td>\n",
       "      <td>03-01-2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.801743</td>\n",
       "      <td>7.081148</td>\n",
       "      <td>36.502882</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>mm_data</td>\n",
       "      <td>03-01-2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.467025</td>\n",
       "      <td>7.130372</td>\n",
       "      <td>36.802389</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>mm_data</td>\n",
       "      <td>03-01-2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.678886</td>\n",
       "      <td>6.195121</td>\n",
       "      <td>35.554442</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>mm_data</td>\n",
       "      <td>03-01-2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.614373</td>\n",
       "      <td>6.096673</td>\n",
       "      <td>36.652635</td>\n",
       "      <td>2018</td>\n",
       "      <td>06</td>\n",
       "      <td>mm_data</td>\n",
       "      <td>03-01-2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rainfall  latitude  longitude  year dekad     type        date  month\n",
       "0  68.930994  4.570738  21.876941  2018    06  mm_data  03-01-2018      3\n",
       "1  89.801743  7.081148  36.502882  2018    06  mm_data  03-01-2018      3\n",
       "2  63.467025  7.130372  36.802389  2018    06  mm_data  03-01-2018      3\n",
       "3  59.678886  6.195121  35.554442  2018    06  mm_data  03-01-2018      3\n",
       "4  71.614373  6.096673  36.652635  2018    06  mm_data  03-01-2018      3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('CHIRPS-combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
